{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b561a31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment ready\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Bachelor Thesis — Fairness in Toxic Comment Classification\n",
    "# ---------------------------------------------------------------\n",
    "# Notebook: data_preprocessing_and_preparation.ipynb\n",
    "# Author: Philipp Stocker\n",
    "# Created: 02.11.2025\n",
    "# Purpose: This notebook handles the preprocessing and preparation of the dataset for model training.\n",
    "# It includes data cleaning, label creation, text vectorization, and train–validation–test splitting,\n",
    "# ensuring that the data is ready for subsequent model development and bias evaluation stages.\n",
    "# ================================================================\n",
    "\n",
    "# --- Basic setup ---\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # keep output clean for reports\n",
    "\n",
    "# Automatically add project root to path so src/ modules are importable\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# --- Standard imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import src.data_preprocessing_and_preparation as data_prep\n",
    "\n",
    "# --- \"Global variables\" ---\n",
    "DATA_RAW = os.path.join(project_root, \"data\", \"raw\")\n",
    "DATA_PROCESSED = os.path.join(project_root, \"data\", \"processed\")\n",
    "\n",
    "IDENTITY_COLUMNS = [\"male\", \"female\", \"heterosexual\", \"homosexual_gay_or_lesbian\", \"bisexual\", \"transgender\", \"other_gender\", \"other_sexual_orientation\"]\n",
    "\n",
    "print(\"✅ Environment ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20981220",
   "metadata": {},
   "source": [
    "DATASET SPLITTING (Creation of training-, test- and validation sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cfab70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1263411, 47) (270731, 47) (270732, 47)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_RAW, \"train.csv\"))\n",
    "\n",
    "train_prepared, test_prepared, validation_prepared = data_prep.split_dataset(df, IDENTITY_COLUMNS) # split dataset into train, test and validation set\n",
    "\n",
    "# Add binary labels for toxicity and presence of identity (for analysis purposes)\n",
    "for d in (train_prepared, test_prepared, validation_prepared):\n",
    "    d = data_prep.binarize_labels(d, target_col=\"target\", new_col_name=\"labelled_as_toxic\", threshold=0.5)\n",
    "    d[\"has_identity\"] = (d[IDENTITY_COLUMNS] > 0.5).any(axis=1).astype(int)\n",
    "\n",
    "print(train_prepared.shape, test_prepared.shape, validation_prepared.shape) # print shapes of the prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4a6dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prepared datasets successfully:\n",
      "- Train: c:\\Users\\phili\\OneDrive\\Dokumente\\Uni\\Kurse\\7. Semester\\Bachelorarbeit\\BA_Arbeitsmappe\\BachelorThesis_BiasInToxicCommentClassification\\data\\processed\\train.csv\n",
      "- Test: c:\\Users\\phili\\OneDrive\\Dokumente\\Uni\\Kurse\\7. Semester\\Bachelorarbeit\\BA_Arbeitsmappe\\BachelorThesis_BiasInToxicCommentClassification\\data\\processed\\test.csv\n",
      "- Validation: c:\\Users\\phili\\OneDrive\\Dokumente\\Uni\\Kurse\\7. Semester\\Bachelorarbeit\\BA_Arbeitsmappe\\BachelorThesis_BiasInToxicCommentClassification\\data\\processed\\validation.csv\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(DATA_PROCESSED, \"train.csv\")\n",
    "test_path = os.path.join(DATA_PROCESSED, \"test.csv\")\n",
    "validation_path = os.path.join(DATA_PROCESSED, \"validation.csv\")\n",
    "\n",
    "# Save prepared datasets to processed data folder\n",
    "train_prepared.to_csv(train_path, index=False)\n",
    "test_prepared.to_csv(test_path, index=False)\n",
    "validation_prepared.to_csv(validation_path, index=False)\n",
    "\n",
    "print(\"Saved prepared datasets successfully:\"\n",
    "      f\"\\n- Train: {train_path}\"\n",
    "      f\"\\n- Test: {test_path}\"\n",
    "      f\"\\n- Validation: {validation_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7aaa6",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING (Comment text cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327bc94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prepared datasets\n",
    "train_df = pd.read_csv(os.path.join(DATA_PROCESSED, \"train.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(DATA_PROCESSED, \"validation.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_PROCESSED, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fada8285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69507eec5c9c4086811e0bda449a38da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1263411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694565f345a546e5b98c5b03fafef20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/270732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b10af4ffd4944c080af666d47e6d236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/270731 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import swifter # for faster apply operations (parallelization)\n",
    "\n",
    "# Clean comment texts by applying text preprocessing function\n",
    "train_df[\"comment_text_processed\"] = train_df[\"comment_text\"].swifter.apply(data_prep.clean_comment)\n",
    "val_df[\"comment_text_processed\"] = val_df[\"comment_text\"].swifter.apply(data_prep.clean_comment)\n",
    "test_df[\"comment_text_processed\"] = test_df[\"comment_text\"].swifter.apply(data_prep.clean_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aba7ed",
   "metadata": {},
   "source": [
    "Peek at processing results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "260109a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ain't it amazing ? Them too-----and Trump stil...</td>\n",
       "      <td>ain't it amazing them too and trump still won ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The owners can discipline the players involved...</td>\n",
       "      <td>the owners can discipline the players involved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comedy. Obama has dealt with single digit unem...</td>\n",
       "      <td>comedy obama has dealt with single digit unemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Likely.   \"His prior convictions include DUI a...</td>\n",
       "      <td>likely his prior convictions include dui and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blaming the tourists for the poor quality of o...</td>\n",
       "      <td>blaming the tourists for the poor quality of o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Ain't it amazing ? Them too-----and Trump stil...   \n",
       "1  The owners can discipline the players involved...   \n",
       "2  comedy. Obama has dealt with single digit unem...   \n",
       "3  Likely.   \"His prior convictions include DUI a...   \n",
       "4  Blaming the tourists for the poor quality of o...   \n",
       "\n",
       "                              comment_text_processed  \n",
       "0  ain't it amazing them too and trump still won ...  \n",
       "1  the owners can discipline the players involved...  \n",
       "2  comedy obama has dealt with single digit unemp...  \n",
       "3  likely his prior convictions include dui and f...  \n",
       "4  blaming the tourists for the poor quality of o...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"comment_text\", \"comment_text_processed\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e065c557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I listened to Scheer re Omar Khadr; he sounded...</td>\n",
       "      <td>i listened to scheer re omar khadr he sounded ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For more on Pre check out; prespeople.com</td>\n",
       "      <td>for more on pre check out prespeople com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They also have to go to places where people sh...</td>\n",
       "      <td>they also have to go to places where people sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is why many experts and policy makers are...</td>\n",
       "      <td>this is why many experts and policy makers are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeah, I know...many regular miles as well.</td>\n",
       "      <td>yeah i know many regular miles as well</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  I listened to Scheer re Omar Khadr; he sounded...   \n",
       "1          For more on Pre check out; prespeople.com   \n",
       "2  They also have to go to places where people sh...   \n",
       "3  This is why many experts and policy makers are...   \n",
       "4         Yeah, I know...many regular miles as well.   \n",
       "\n",
       "                              comment_text_processed  \n",
       "0  i listened to scheer re omar khadr he sounded ...  \n",
       "1           for more on pre check out prespeople com  \n",
       "2  they also have to go to places where people sh...  \n",
       "3  this is why many experts and policy makers are...  \n",
       "4             yeah i know many regular miles as well  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[[\"comment_text\", \"comment_text_processed\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19813403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"The rumour at the time was that the RCMP has ...</td>\n",
       "      <td>the rumour at the time was that the rcmp has a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may jest, but Amazon offering to allow pur...</td>\n",
       "      <td>you may jest but amazon offering to allow purv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are completely out to lunch! There is abso...</td>\n",
       "      <td>you are completely out to lunch there is absol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good decision. This decision is probably savin...</td>\n",
       "      <td>good decision this decision is probably saving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would suggest REITs, especially those invest...</td>\n",
       "      <td>i would suggest reits especially those investi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  \"The rumour at the time was that the RCMP has ...   \n",
       "1  You may jest, but Amazon offering to allow pur...   \n",
       "2  You are completely out to lunch! There is abso...   \n",
       "3  Good decision. This decision is probably savin...   \n",
       "4  I would suggest REITs, especially those invest...   \n",
       "\n",
       "                              comment_text_processed  \n",
       "0  the rumour at the time was that the rcmp has a...  \n",
       "1  you may jest but amazon offering to allow purv...  \n",
       "2  you are completely out to lunch there is absol...  \n",
       "3  good decision this decision is probably saving...  \n",
       "4  i would suggest reits especially those investi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[[\"comment_text\", \"comment_text_processed\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f2128",
   "metadata": {},
   "source": [
    "Save processed dataframes (to CSV and parquet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e773ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed dataframes to parquet (more efficient storage format)\n",
    "train_df.to_parquet(os.path.join(DATA_PROCESSED, \"train_processed.parquet\"), index=False)\n",
    "val_df.to_parquet(os.path.join(DATA_PROCESSED, \"validation_processed.parquet\"), index=False)\n",
    "test_df.to_parquet(os.path.join(DATA_PROCESSED, \"test_processed.parquet\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a09c1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed dataframes to CSV as well (for easier inspection)\n",
    "train_df.to_csv(os.path.join(DATA_PROCESSED, \"train_processed.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(DATA_PROCESSED, \"validation_processed.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(DATA_PROCESSED, \"test_processed.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83963982",
   "metadata": {},
   "source": [
    "DATA VECTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceb526b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed dataframes from parquet files\n",
    "train_df = pd.read_parquet(os.path.join(DATA_PROCESSED, \"train_processed.parquet\"))\n",
    "val_df = pd.read_parquet(os.path.join(DATA_PROCESSED, \"validation_processed.parquet\"))\n",
    "test_df = pd.read_parquet(os.path.join(DATA_PROCESSED, \"test_processed.parquet\"))\n",
    "\n",
    "# Ensure that processed comment texts are strings and handle any missing values\n",
    "train_df[\"comment_text_processed\"] = train_df[\"comment_text_processed\"].astype(str).fillna(\"\")\n",
    "val_df[\"comment_text_processed\"]   = val_df[\"comment_text_processed\"].astype(str).fillna(\"\")\n",
    "test_df[\"comment_text_processed\"]  = test_df[\"comment_text_processed\"].astype(str).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37a31ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "      <th>labelled_as_toxic</th>\n",
       "      <th>has_identity</th>\n",
       "      <th>comment_text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>812993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ain't it amazing ? Them too-----and Trump stil...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ain't it amazing them too and trump still won ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6027970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The owners can discipline the players involved...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the owners can discipline the players involved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348458</td>\n",
       "      <td>0.2</td>\n",
       "      <td>comedy. Obama has dealt with single digit unem...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>comedy obama has dealt with single digit unemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5368848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Likely.   \"His prior convictions include DUI a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>likely his prior convictions include dui and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5862887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Blaming the tourists for the poor quality of o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>blaming the tourists for the poor quality of o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  target                                       comment_text  \\\n",
       "0   812993     0.0  Ain't it amazing ? Them too-----and Trump stil...   \n",
       "1  6027970     0.0  The owners can discipline the players involved...   \n",
       "2   348458     0.2  comedy. Obama has dealt with single digit unem...   \n",
       "3  5368848     0.0  Likely.   \"His prior convictions include DUI a...   \n",
       "4  5862887     0.0  Blaming the tourists for the poor quality of o...   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack  insult  threat  asian  atheist  \\\n",
       "0              0.0      0.0              0.0     0.0     0.0    NaN      NaN   \n",
       "1              0.0      0.0              0.0     0.0     0.0    NaN      NaN   \n",
       "2              0.0      0.0              0.0     0.2     0.0    0.0      0.0   \n",
       "3              0.0      0.0              0.0     0.0     0.0    NaN      NaN   \n",
       "4              0.0      0.0              0.0     0.0     0.0    NaN      NaN   \n",
       "\n",
       "   ...  wow  sad  likes  disagree  sexual_explicit  identity_annotator_count  \\\n",
       "0  ...    0    0      4         1              0.0                         0   \n",
       "1  ...    0    0      6         1              0.0                         0   \n",
       "2  ...    0    0      1         0              0.0                         4   \n",
       "3  ...    0    1      0         0              0.0                         0   \n",
       "4  ...    0    0     12         0              0.0                         0   \n",
       "\n",
       "   toxicity_annotator_count  labelled_as_toxic  has_identity  \\\n",
       "0                         4                  0             0   \n",
       "1                         4                  0             0   \n",
       "2                         5                  0             0   \n",
       "3                         4                  0             0   \n",
       "4                         4                  0             0   \n",
       "\n",
       "                              comment_text_processed  \n",
       "0  ain't it amazing them too and trump still won ...  \n",
       "1  the owners can discipline the players involved...  \n",
       "2  comedy obama has dealt with single digit unemp...  \n",
       "3  likely his prior convictions include dui and f...  \n",
       "4  blaming the tourists for the poor quality of o...  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows of processed dataframes before vectorization\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc987ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build TF-IDF vectorizer based on training data (with standard parameters)\n",
    "vectorizer = data_prep.build_tfidf_vectorizer()\n",
    "\n",
    "# extract necessary columns for model training and evaluation\n",
    "x_train = train_df[\"comment_text_processed\"]\n",
    "y_train = train_df[\"labelled_as_toxic\"]\n",
    "\n",
    "x_val = val_df[\"comment_text_processed\"]\n",
    "y_val = val_df[\"labelled_as_toxic\"]\n",
    "\n",
    "x_test = test_df[\"comment_text_processed\"]\n",
    "y_test = test_df[\"labelled_as_toxic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7af43",
   "metadata": {},
   "source": [
    "Apply data transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe7fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply transformation\n",
    "x_train_vec = vectorizer.fit_transform(x_train) # use fit (Learns the vocabulary and IDF weights) only on training data to avoid data leakage\n",
    "x_val_vec   = vectorizer.transform(x_val) \n",
    "x_test_vec  = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cfb7230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (train/val/test): (1263411, 1039908) (270732, 1039908) (270731, 1039908)\n"
     ]
    }
   ],
   "source": [
    "# print shapes of the resulting vectors\n",
    "print(\"Shapes (train/val/test):\", x_train_vec.shape, x_val_vec.shape, x_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba73a84",
   "metadata": {},
   "source": [
    "Save vectorizer and bundles of vectorized data + its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e6bdd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\phili\\\\OneDrive\\\\Dokumente\\\\Uni\\\\Kurse\\\\7. Semester\\\\Bachelorarbeit\\\\BA_Arbeitsmappe\\\\BachelorThesis_BiasInToxicCommentClassification/data/processed/test_tfidf_bundle.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib # for saving models and data bundles efficiently\n",
    "\n",
    "# Save the vectorizer for later use\n",
    "joblib.dump(vectorizer, project_root + \"/models/tfidf_vectorizer.joblib\")\n",
    "\n",
    "# Save bundles of vectorized data + its label\n",
    "joblib.dump(\n",
    "    {\"x\": x_train_vec, \"y\": y_train},\n",
    "    project_root + \"/data/processed/train_tfidf_bundle.joblib\"\n",
    ")\n",
    "\n",
    "joblib.dump(\n",
    "    {\"x\": x_val_vec, \"y\": y_val},\n",
    "    project_root + \"/data/processed/val_tfidf_bundle.joblib\"\n",
    ")\n",
    "\n",
    "joblib.dump(\n",
    "    {\"x\": x_test_vec, \"y\": y_test},\n",
    "    project_root + \"/data/processed/test_tfidf_bundle.joblib\"\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
