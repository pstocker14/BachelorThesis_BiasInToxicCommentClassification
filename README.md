# BA Thesis: Mitigating Bias in Toxic Comment Classification

**Author:** Philipp Stocker  
**Start date:** 2025-10-01  
**Created scaffold:** 2025-10-18  
**Project end date:** 2026-01-12

## Overview

This repository contains code and materials for a bachelor's thesis from the course "Digitalization-Innovation-Society" of the University of Salzburg. The project investigates bias in machine learning models used for toxic comment classification, with a focus on biases against LGBTQ identities. The study employs the Jigsaw Unintended Bias in Toxicity Classification dataset, which includes comments labeled for toxicity and various identity attributes.

### Objectives
- Detect and quantify bias in baseline toxicity classification models.
- Implement and evaluate bias mitigation techniques to reduce unfair treatment of protected groups.
- Compare the performance and fairness of different mitigation approaches.

### Methods
- **Data Preprocessing:** Text cleaning, tokenization, and feature extraction using TF-IDF vectorization.
- **Modeling:** Logistic regression models trained on TF-IDF features.
- **Bias Mitigation Techniques:**
  - **Baseline Model:** Standard training without mitigation.
  - **Counterfactual Data Augmentation (CDA):** Augmenting data with counterfactual examples to reduce bias.
  - **Fairness-Constrained Learning (FCL):** Incorporating fairness constraints during training.
  - **Equalized Odds (EO):** Post-processing adjustments to achieve equalized odds across subgroups.
- **Evaluation:** Overall accuracy, precision, recall, F1-score, ROC-AUC, PR-AUC, and subgroup-specific metrics for bias assessment.

### Project Structure
- `data/`: Raw and processed datasets, including TF-IDF bundles.
- `models/`: Trained model files and TF-IDF vectorizers.
- `notebooks/`: Jupyter notebooks for data exploration, preprocessing, model training, and evaluation.
- `results/`: Evaluation metrics and performance results.
- `src/`: Source code for preprocessing, modeling, metrics, visualization, and bias mitigation.

## Table of Contents

- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Project Structure](#project-structure)
- [Data](#data)
- [Usage](#usage)
- [Reproducibility](#reproducibility)
- [License](#license)

## Prerequisites

- Python 3.9 or higher
- Conda (for environment management)
- Git

## Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/pstocker14/BachelorThesis_BiasInToxicCommentClassification.git
   cd BachelorThesis_BiasInToxicCommentClassification
   ```

2. **Set up the Conda environment:**
   ```bash
   # Create a new conda environment
   conda create -n bias_mitigation_env python=3.9

   # Activate the environment
   conda activate bias_mitigation_env

   # Install dependencies
   pip install -r requirements.txt
   ```

## Project Structure

```
BachelorThesis_BiasInToxicCommentClassification/
├── data/
│   ├── raw/          # Unaltered source data (read-only)
│   └── processed/    # Cleaned/derived datasets for modeling
├── models/           # Trained models and vectorizers
├── notebooks/        # Jupyter notebooks for analysis, training, and evaluation
├── results/          # Files containing the bias and performance results of evry model
├── src/              # Reusable Python modules
├── requirements.txt  # Python dependencies
├── README.md         # This file
└── .gitignore        # Ignore patterns
```

## Data

The project uses the Jigsaw *Unintended Bias in Toxicity Classification* dataset. The raw data should be placed in `data/raw/`. Due to size and licensing, the data is not included in this repository.

- Download the dataset from [Kaggle](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data).
- Place the files in `data/raw/`.

Processed data is generated by running the preprocessing notebooks.

## Usage

1. Ensure the environment is activated: `conda activate bias_mitigation_env`
2. Run Jupyter notebooks in the `notebooks/` directory for data exploration, preprocessing, training, and evaluation.
3. The notebooks call different functions from python-files in `src/` which can be adapted via different parameter settings.
4. Each model/mitigation technique has its own notebook including various cells for both performance and fairness evaluations.
   Cross evaluations can either be done separately or via the plots generated in `print_final_thesis_plots.ipynb`.

Example to run a notebook:
```bash
jupyter notebook notebooks/data_exploration_and_analysis.ipynb
```

## Reproducibility

To reproduce the results:

1. Follow the installation steps above.
2. Download and place the dataset as described in [Data](#data).
3. Run the notebooks in order:
   - `data_exploration_and_analysis.ipynb`
   - `data_preprocessing_and_preparation.ipynb`
   - Training notebooks (e.g., `base_model_training_and_evaluation.ipynb`, etc.)
   - `print_final_thesis_plots.ipynb` for final plots (optional).

All random seeds are set for reproducibility. Results are saved in `results/` and models in `models/`.

## License

This project is for academic purposes.

